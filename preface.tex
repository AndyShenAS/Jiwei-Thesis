\prefacesection{Abstract}
The ability of a machine to communicate with humans has long been associated with the general success of AI. This dates back to 
Alan Turing's epoch-making work in 
the early 1950s, 
which proposes that  
a machine's intelligence 
can be tested by 
how well it, the machine, can fool a human
into believing that the machine is a human through dialogue conversations. 
Despite progress in the field of dialogue learning over the past decades, 
conventional dialog
systems 
still 
face a variety of major challenges such as robustness, scalability and domain adaptation: 
many systems 
 learn generation
rules from a minimal set of authored rules or
labels on top of  handcoded
rules or templates, and thus are both expensive
and difficult to extend to open-domain scenarios.
Meanwhile, dialogue systems have become increasingly 
complicated: they usually involve building many different complex components separately, rendering them unable to accommodate 
the large amount of data that we have to date. 

Recently, the emergence of neural network models the potential to solve many of the  problems 
in dialogue learning
that earlier systems cannot tackle:
the end-to-end neural frameworks
offer the promise of scalability
and language-independence,  together with the
ability to track the dialogue state and 
then mapping between states and dialogue actions
 in a way not possible with conventional 
systems.   
On the other hand,  neural systems  bring about new challenges: 
they tend to output dull and generic responses such as ``I don't know what you are talking about"; they lack a consistent or a coherent persona; they are usually optimized through single-turn conversations and are incapable of handling the long-term success of a conversation; and they are not able to take the advantage of the interactions with humans.


This dissertation 
attempts to tackle these challenges:
Contributions are twofold: 
(1) we address new challenges presented by  neural network models in open-domain dialogue generation systems, which includes (a) using mutual information to avoid dull and generic responses; (b) addressing user consistency issues to avoid inconsistent responses generated by the same user; (c) developing reinforcement learning 
methods to foster the long-term success of conversations; and (d) using adversarial learning methods to push machines to generate responses that are indistinguishable from human-generated responses; 
(2) we develop interactive 
question-answering
dialogue  systems by
(a) giving the agent the ability to ask questions and (b) training a conversation agent through interactions with humans in an
online fashion, where a bot improves through communicating with humans and  learning from the mistakes
that it makes. 


%This dissertation describes a new technique for learning open-domain knowledge from unstructured web-scale text corpora,
%  making use of a probabilistic relaxation of natural logic -- 
%  a logic which uses the syntax of natural language as its logical formalism.
%We begin by reviewing the theory behind natural logic, and propose a novel extension of the logic to handle
%  propositional formulae.
%
%We then show how to capture common sense facts: given a candidate statement about the world and a large corpus of 
%  known facts, is the statement likely to be true? 
%This is treated as a search problem 
%  from the query statement to its appropriate support in the knowledge base over valid (or approximately valid) 
%  natural logical inference steps.
%This approach achieves a 4x improvement at retrieval recall compared to lemmatized lookup, 
%  maintaining above 90\% precision.
%
%We then extend the approach to handle longer, more complex premises by segmenting these utterance into a set of 
%  atomic statements entailed through natural logic.
%We evaluate this system in isolation by using it as the main component in an Open Information Extraction system, 
%  and show that it achieves a 3\% absolute improvement in F1 compared to prior work on a competitive knowledge 
%  base population task.
%
%Finally, we address how to elegantly handle situations where we could not find a supporting premise for our query.
%To address this, we create an analogue of an evaluation function in gameplaying search: a shallow lexical 
%  classifier is folded into the search program to serve as a heuristic function to assess how likely we would 
%  have been to find a premise.
%Results on answering 4th grade science questions show that this method improves over both the classifier in isolation, 
%  a strong IR baseline, and prior work.
